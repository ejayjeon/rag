# src/interfaces/streamlit_app.py
import streamlit as st
import tempfile
import os
import sys
import time
from pathlib import Path
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€ (ë°°í¬ í™˜ê²½ ëŒ€ì‘)
# Streamlit Cloudì™€ ë¡œì»¬ í™˜ê²½ ëª¨ë‘ í˜¸í™˜ë˜ëŠ” ë°©ì‹
current_dir = Path.cwd()
file_dir = Path(__file__).parent

# ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë“¤ í™•ì¸
possible_roots = [
    file_dir,  # streamlit_app.pyê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ (ë¡œì»¬)
    current_dir,  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ (Streamlit Cloud)
    Path("/mount/src/rag/stt-project/backend"),  # Streamlit Cloud ì ˆëŒ€ ê²½ë¡œ
]

project_root = None
for root in possible_roots:
    if root.exists() and (root / "src").exists():
        project_root = root
        break

if project_root is None:
    # fallback: í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©
    project_root = current_dir

# Python pathì— ì¶”ê°€
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from src.services.voice_service import VoiceProcessingService
from src.core.config import Config
from src.chains.llm_factory import LLMFactory

# í™˜ê²½ ë³€ìˆ˜ ë° LLM ì—°ê²° ìƒíƒœ í™•ì¸
def check_environment():
    """í™˜ê²½ ë³€ìˆ˜ ë° LLM ì—°ê²° ìƒíƒœ í™•ì¸"""
    env_status = {}
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    env_status['LLM_PROVIDER'] = os.getenv('LLM_PROVIDER', 'Not Set')
    env_status['OPENAI_API_KEY'] = "âœ… Set" if os.getenv('OPENAI_API_KEY') else "âŒ Not Set"
    env_status['OLLAMA_BASE_URL'] = os.getenv('OLLAMA_BASE_URL', 'Not Set')
    
    # LLM ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        provider_info = LLMFactory.get_provider_info()
        env_status['LLM_Status'] = provider_info['status']
        env_status['LLM_Model'] = provider_info['model']
    except Exception as e:
        env_status['LLM_Status'] = f"âŒ Error: {str(e)}"
        env_status['LLM_Model'] = "Unknown"
    
    return env_status

# ë°°í¬ ë””ë²„ê·¸ ì •ë³´ (ë°°í¬ í™˜ê²½ì—ì„œ í™•ì¸ìš©)
with st.expander("ğŸ” **ë°°í¬ ë””ë²„ê·¸ ì •ë³´**", expanded=False):
    st.write(f"**í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬**: {Path.cwd()}")
    st.write(f"**íŒŒì¼ ìœ„ì¹˜**: {Path(__file__)}")
    st.write(f"**ì„ íƒëœ í”„ë¡œì íŠ¸ ë£¨íŠ¸**: {project_root}")
    st.write(f"**src í´ë” ì¡´ì¬ ì—¬ë¶€**: {(project_root / 'src').exists()}")
    
    # í™˜ê²½ ë³€ìˆ˜ ìƒíƒœ í™•ì¸
    st.write("### ğŸ”§ í™˜ê²½ ë³€ìˆ˜ ìƒíƒœ")
    env_status = check_environment()
    for key, value in env_status.items():
        st.write(f"**{key}**: {value}")

st.write("---")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ™ï¸ ìŒì„± ì²˜ë¦¬ ì‹œìŠ¤í…œ",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ì •ë³´
def render_sidebar():
    with st.sidebar:
        st.markdown("## ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")
        
        # LLM ì œê³µì ì„ íƒ
        st.markdown("## ğŸ¤– LLM ì œê³µì ì„¤ì •")
        
        # í˜„ì¬ ì„¤ì • í™•ì¸
        current_provider = Config.get_current_llm_provider().value
        llm_config = Config.get_llm_config()
        
        # ì œê³µì ì„ íƒ
        provider_options = ["ollama", "openai"]
        provider_labels = {"ollama": "ğŸ¦™ Ollama (ë¡œì»¬)", "openai": "ğŸ¤– OpenAI API"}
        
        selected_provider = st.selectbox(
            "LLM ì œê³µì ì„ íƒ",
            options=provider_options,
            index=provider_options.index(current_provider),
            format_func=lambda x: provider_labels[x]
        )
        
        # í™˜ê²½ë³€ìˆ˜ë¡œ ì œê³µì ì„¤ì • ì•ˆë‚´
        if selected_provider != current_provider:
            st.info(f"""
            ğŸ’¡ **ì œê³µì ë³€ê²½**
            
            í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
            ```
            LLM_PROVIDER={selected_provider}
            ```
            ë˜ëŠ” ë°°í¬ í™˜ê²½ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.
            """)
        
        # ì œê³µìë³„ ìƒíƒœ í‘œì‹œ
        if selected_provider == "ollama":
            try:
                import requests
                response = requests.get(Config.OLLAMA_BASE_URL, timeout=5)
                if response.status_code == 200:
                    st.success(f"ğŸ¦™ Ollama ì—°ê²°ë¨ ({Config.OLLAMA_MODEL})")
                else:
                    st.error("âŒ Ollama ì—°ê²° ì‹¤íŒ¨")
            except:
                st.error("âŒ Ollama ì„œë²„ ì—†ìŒ")
                st.code("ollama serve")
        
        elif selected_provider == "openai":
            if Config.is_openai_configured():
                st.success(f"ğŸ¤– OpenAI API ì„¤ì •ë¨ ({Config.OPENAI_MODEL})")
            else:
                st.error("âŒ OpenAI API í‚¤ ì—†ìŒ")
                st.info("""
                í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”:
                ```
                OPENAI_API_KEY=your_api_key_here
                ```
                """)
        
        # ì„¤ì • ì •ë³´
        st.markdown("---")
        st.markdown("## âš™ï¸ ì²˜ë¦¬ ì„¤ì •")
        try:
            st.info(f"""
            **STT ëª¨ë¸**: {Config.WHISPER_MODEL}
            **ì–¸ì–´**: {Config.WHISPER_LANGUAGE}
            **ìµœëŒ€ íŒŒì¼ í¬ê¸°**: {Config.MAX_AUDIO_SIZE_MB}MB
            **LLM ì œê³µì**: {llm_config['provider']}
            **LLM ëª¨ë¸**: {llm_config['model']}
            """)
        except NameError:
            st.info("""
            **STT ëª¨ë¸**: base
            **ì–¸ì–´**: ko
            **ìµœëŒ€ íŒŒì¼ í¬ê¸°**: 50MB
            **LLM ì œê³µì**: ollama
            **LLM ëª¨ë¸**: llama2
            """)
        
        st.markdown("---")
        st.markdown("## ğŸ“‹ ì²˜ë¦¬ ë‹¨ê³„")
        st.info("""
        1. **STT**: Whisperë¡œ ìŒì„±â†’í…ìŠ¤íŠ¸
        2. **ì •ë¦¬**: ìŠµê´€ì–´ ì œê±°
        3. **êµ¬ì¡°í™”**: ë¬¸ë‹¨ë³„ ì •ë¦¬
        4. **íƒœê·¸**: í•´ì‹œíƒœê·¸ ì¶”ì¶œ
        """)

def main():
    # ì œëª©
    st.title("ğŸ™ï¸ ìŒì„± ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    st.markdown("### ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ìŠ¤í† ë¦¬ë¥¼ ì •ë¦¬í•´ë³´ì„¸ìš”!")
    
    # ì‚¬ì´ë“œë°” ë Œë”ë§
    render_sidebar()
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í˜„ì¬ ì„ íƒëœ provider ì‚¬ìš©)
    @st.cache_resource
    def get_voice_service(provider: str):
        try:
            return VoiceProcessingService(llm_provider=provider)
        except Exception as e:
            st.error(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return None
    
    # í˜„ì¬ ì„¤ì •ëœ providerë¡œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    current_provider = Config.get_current_llm_provider().value
    voice_service = get_voice_service(current_provider)
    if voice_service is None:
        st.stop()
    
    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    st.markdown("## ğŸ“¤ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ")
    
    # íŒŒì¼ ì—…ë¡œë”
    uploaded_file = st.file_uploader(
        "ìŒì„± íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['wav', 'mp3', 'mp4', 'm4a', 'flac', 'ogg'],
        help=f"ìµœëŒ€ íŒŒì¼ í¬ê¸°: {Config.MAX_AUDIO_SIZE_MB}MB"
    )
    
    # ìƒ˜í”Œ íŒŒì¼ ì˜µì…˜ (ê°œë°œìš©)
    st.markdown("---")
    with st.expander("ğŸ§ ìƒ˜í”Œ íŒŒì¼ í…ŒìŠ¤íŠ¸"):
        if st.button("ìƒ˜í”Œ ìŒì„± ìƒì„± (ê°œë°œìš©)"):
            # ê°œë°œìš© ìƒ˜í”Œ í…ìŠ¤íŠ¸
            sample_text = "ì•ˆë…•í•˜ì„¸ìš”. ìŒ... ì˜¤ëŠ˜ì€ ì •ë§ ì¢‹ì€ ë‚ ì”¨ë„¤ìš”. ê·¸... ì•„ì¹¨ì— ê³µì›ì„ ì‚°ì±…í–ˆëŠ”ë° ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•˜ì–´ìš”. ì–´... ìƒˆë“¤ì´ ì§€ì €ê·€ê³  ê½ƒë“¤ì´ ì˜ˆì˜ê²Œ í”¼ì–´ìˆë”ë¼ê³ ìš”."
            
            # ì„ì‹œë¡œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ë§Œ í…ŒìŠ¤íŠ¸
            st.session_state['sample_text'] = sample_text
            st.success("ìƒ˜í”Œ í…ìŠ¤íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì²˜ë¦¬ ì‹¤í–‰
    if uploaded_file is not None or st.session_state.get('sample_text'):
        st.markdown("---")
        
        # ì²˜ë¦¬ ë²„íŠ¼
        col1, col2 = st.columns([1, 4])
        with col1:
            process_button = st.button(
                "ğŸš€ ì²˜ë¦¬ ì‹œì‘", 
                type="primary",
                use_container_width=True
            )
        
        if process_button:
            # ì²˜ë¦¬ ì‹œì‘
            with st.spinner('ğŸ”„ ìŒì„±ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    if uploaded_file:
                        # ì‹¤ì œ ìŒì„± íŒŒì¼ ì²˜ë¦¬
                        status_text.text("ğŸ“ íŒŒì¼ì„ ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        progress_bar.progress(0.1)
                        
                        # ì²˜ë¦¬ ì‹¤í–‰
                        result = voice_service.process_uploaded_audio(
                            uploaded_file, 
                            uploaded_file.name
                        )
                        
                    elif st.session_state.get('sample_text'):
                        # ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ (STT ê±´ë„ˆë›°ê¸°)
                        status_text.text("ğŸ“ ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        progress_bar.progress(0.3)
                        
                        # ì„ì‹œ ê²°ê³¼ ìƒì„± (ê°œë°œìš©)
                        from src.core.state import ProcessingResult
                        
                        result = ProcessingResult(
                            success=True,
                            session_id="sample_session",
                            original_text=st.session_state['sample_text'],
                            cleaned_text=st.session_state['sample_text'].replace("ìŒ...", "").replace("ê·¸...", "").replace("ì–´...", ""),
                            organized_story={
                                "title": "ê³µì› ì‚°ì±… ì´ì•¼ê¸°",
                                "summary": "ì•„ì¹¨ ê³µì› ì‚°ì±…ì—ì„œ ëŠë‚€ ì¢‹ì€ ê¸°ë¶„",
                                "sections": [
                                    {
                                        "section_title": "ì•„ì¹¨ ì‚°ì±…",
                                        "content": "ì•„ì¹¨ì— ê³µì›ì„ ì‚°ì±…í–ˆëŠ”ë° ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•˜ì–´ìš”.",
                                        "key_points": ["ê³µì› ì‚°ì±…", "ì¢‹ì€ ê¸°ë¶„"]
                                    },
                                    {
                                        "section_title": "ìì—° ê°ìƒ",
                                        "content": "ìƒˆë“¤ì´ ì§€ì €ê·€ê³  ê½ƒë“¤ì´ ì˜ˆì˜ê²Œ í”¼ì–´ìˆë”ë¼ê³ ìš”.",
                                        "key_points": ["ìƒˆ ì†Œë¦¬", "ê½ƒ"]
                                    }
                                ]
                            },
                            tags=["#ê³µì›", "#ì‚°ì±…", "#ì•„ì¹¨", "#ìì—°", "#ì¢‹ì€ë‚ ì”¨"]
                        )
                    
                    progress_bar.progress(1.0)
                    status_text.text("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                    
                    # ê²°ê³¼ ì €ì¥ (ì„¸ì…˜ ìƒíƒœ)
                    st.session_state['processing_result'] = result
                    
                except Exception as e:
                    st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.exception(e)  # ê°œë°œ ì¤‘ì—ëŠ” ìƒì„¸ ì—ëŸ¬ í‘œì‹œ
    
    # ê²°ê³¼ í‘œì‹œ
    if 'processing_result' in st.session_state:
        result = st.session_state['processing_result']
        
        st.markdown("---")
        st.markdown("## ğŸ“Š ì²˜ë¦¬ ê²°ê³¼")
        
        if result.success:
            # ì„±ê³µ ê²°ê³¼ í‘œì‹œ
            st.balloons()
            
            # ê²°ê³¼ ìš”ì•½
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸", f"{len(result.original_text)}ì")
            with col2:
                st.metric("âœ¨ ì •ë¦¬ëœ í…ìŠ¤íŠ¸", f"{len(result.cleaned_text)}ì")
            with col3:
                reduction = len(result.original_text) - len(result.cleaned_text)
                st.metric("ğŸ¯ ì •ë¦¬ íš¨ê³¼", f"-{reduction}ì")
            with col4:
                st.metric("ğŸ·ï¸ í•´ì‹œíƒœê·¸", f"{len(result.tags)}ê°œ")
            
            # íƒ­ìœ¼ë¡œ ê²°ê³¼ êµ¬ë¶„ í‘œì‹œ
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ í…ìŠ¤íŠ¸ ë¹„êµ", "ğŸ“– ìŠ¤í† ë¦¬ êµ¬ì¡°", "ğŸ·ï¸ í•´ì‹œíƒœê·¸", "ğŸ” ìƒì„¸ ì •ë³´"])
            
            with tab1:
                st.markdown("### ğŸ“ í…ìŠ¤íŠ¸ ë³€í™”")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ğŸ”´ ì›ë³¸ í…ìŠ¤íŠ¸**")
                    st.text_area(
                        "ì›ë³¸",
                        result.original_text,
                        height=200,
                        disabled=True,
                        key="original"
                    )
                
                with col2:
                    st.markdown("**ğŸŸ¢ ì •ë¦¬ëœ í…ìŠ¤íŠ¸**")
                    st.text_area(
                        "ì •ë¦¬ë³¸",
                        result.cleaned_text,
                        height=200,
                        disabled=True,
                        key="cleaned"
                    )
            
            with tab2:
                st.markdown("### ğŸ“– êµ¬ì¡°í™”ëœ ìŠ¤í† ë¦¬")
                
                if result.organized_story:
                    # ì œëª©ê³¼ ìš”ì•½
                    st.markdown(f"**ì œëª©**: {result.organized_story.get('title', 'ì œëª© ì—†ìŒ')}")
                    st.markdown(f"**ìš”ì•½**: {result.organized_story.get('summary', 'ìš”ì•½ ì—†ìŒ')}")
                    
                    # ì„¹ì…˜ë“¤
                    if 'sections' in result.organized_story:
                        st.markdown("**ì„¹ì…˜ë“¤**:")
                        for i, section in enumerate(result.organized_story['sections']):
                            with st.expander(f"ğŸ“‘ {section.get('section_title', f'ì„¹ì…˜ {i+1}')}"):
                                st.write(section.get('content', 'ë‚´ìš© ì—†ìŒ'))
                                
                                if section.get('key_points'):
                                    st.markdown("**í•µì‹¬ í¬ì¸íŠ¸**:")
                                    for point in section['key_points']:
                                        st.markdown(f"â€¢ {point}")
                else:
                    st.info("êµ¬ì¡°í™”ëœ ìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab3:
                st.markdown("### ğŸ·ï¸ ì¶”ì¶œëœ í•´ì‹œíƒœê·¸")
                
                if result.tags:
                    # í•´ì‹œíƒœê·¸ë¥¼ ì˜ˆì˜ê²Œ í‘œì‹œ
                    tag_html = " ".join([
                        f'<span style="background-color: #e1f5fe; color: #000000; padding: 4px 8px; border-radius: 12px; margin: 2px; display: inline-block; font-weight: 500;">{tag}</span>'
                        for tag in result.tags
                    ])
                    st.markdown(tag_html, unsafe_allow_html=True)
                    
                    # ë³µì‚¬ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸
                    st.markdown("**ë³µì‚¬ìš©**:")
                    tag_text = " ".join(result.tags)
                    st.code(tag_text)
                else:
                    st.info("ì¶”ì¶œëœ í•´ì‹œíƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab4:
                st.markdown("### ğŸ” ì²˜ë¦¬ ìƒì„¸ ì •ë³´")
                
                # ì„¸ì…˜ ì •ë³´
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ì„¸ì…˜ ID**")
                    st.code(result.session_id)
                
                with col2:
                    st.markdown("**ì²˜ë¦¬ ì‹œê°„**")
                    st.code(result.created_at)
                
                # ì²˜ë¦¬ ì •ë³´
                if result.processing_info:
                    st.markdown("**ì²˜ë¦¬ ì •ë³´**")
                    st.json(result.processing_info)
        
        else:
            # ì‹¤íŒ¨ ê²°ê³¼ í‘œì‹œ
            st.error("âŒ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.error(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {result}")
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ**")
        st.caption("Whisper, LangChain, LangGraph, Streamlit")
    
    with col2:
        st.markdown("**âš¡ ì²˜ë¦¬ ê³¼ì •**")
        st.caption("STT â†’ ì •ë¦¬ â†’ êµ¬ì¡°í™” â†’ íƒœê¹…")
    
    with col3:
        st.markdown("**ğŸ¯ ë‹¤ìŒ ë‹¨ê³„**")
        st.caption("FastAPI ì„œë²„í™” â†’ Flutter ì•± ì—°ë™")

# # ê°œë°œ ë””ë²„ê¹… ì •ë³´ (ì‚¬ì´ë“œë°” í•˜ë‹¨)
# def render_debug_info():
#     with st.sidebar:
#         st.markdown("---")
#         with st.expander("ğŸ”§ ë””ë²„ê·¸ ì •ë³´"):
#             st.markdown("**Python ë²„ì „**")
#             import sys
#             st.code(f"{sys.version}")
            
#             st.markdown("**ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ í™•ì¸**")
#             try:
#                 import whisper
#                 st.success("âœ… Whisper ì„¤ì¹˜ë¨")
#             except ImportError:
#                 st.error("âŒ Whisper ì—†ìŒ")
            
#             try:
#                 import langchain
#                 st.success("âœ… LangChain ì„¤ì¹˜ë¨")
#             except ImportError:
#                 st.error("âŒ LangChain ì—†ìŒ")
            
#             try:
#                 import langgraph
#                 st.success("âœ… LangGraph ì„¤ì¹˜ë¨")
#             except ImportError:
#                 st.error("âŒ LangGraph ì—†ìŒ")

if __name__ == "__main__":
    # ê°œë°œ ì¤‘ì—ëŠ” ë””ë²„ê·¸ ì •ë³´ë„ í‘œì‹œ
    # render_debug_info()
    main()
    
    # ê°œë°œìš© ë¦¬ì…‹ ë²„íŠ¼ (ì‚¬ì´ë“œë°”)
    with st.sidebar:
        st.markdown("---")
        if st.button("ğŸ”„ ê²°ê³¼ ì´ˆê¸°í™”"):
            if 'processing_result' in st.session_state:
                del st.session_state['processing_result']
            if 'sample_text' in st.session_state:
                del st.session_state['sample_text']
            st.rerun()