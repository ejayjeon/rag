"""Streamlit web interface for Multimodal RAG"""
import streamlit as st
import tempfile
from pathlib import Path
import os

# ì•ˆì „í•œ import with í´ë°±
try:
    from PIL import Image
except ImportError:
    Image = None

# src ëª¨ë“ˆ ì•ˆì „ import
try:
    from src.multimodal_rag import MultimodalRAG
    MULTIMODAL_RAG_AVAILABLE = True
except ImportError as e:
    MultimodalRAG = None
    MULTIMODAL_RAG_AVAILABLE = False
    IMPORT_ERROR = str(e)

# try:
from src.utils import check_ollama_status, get_ollama_models
# except ImportError:
#     def check_ollama_status():
#         return False
#     def get_ollama_models():
#         return []


# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ–¼ï¸ ë©€í‹°ëª¨ë‹¬ RAG",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ–¼ï¸ ë©€í‹°ëª¨ë‹¬ RAG - í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í†µí•© ê²€ìƒ‰")

# ì˜ì¡´ì„± í™•ì¸
if not MULTIMODAL_RAG_AVAILABLE:
    st.error("âŒ MultimodalRAG ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.error(f"ì˜¤ë¥˜: {IMPORT_ERROR}")
    st.info("í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
    st.code("pip install langchain langchain-community langchain-ollama chromadb sentence-transformers")
    st.stop()

# ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ìƒíƒœ
with st.sidebar:
    st.markdown("## ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    
    # Ollama ìƒíƒœ í™•ì¸
    ollama_status = check_ollama_status()
    if ollama_status:
        st.success("ğŸ¦™ Ollama ì—°ê²°ë¨")
    else:
        st.error("âŒ Ollama ì—°ê²° ì‹¤íŒ¨")
        st.info("Ollamaë¥¼ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”:")
        st.code("ollama serve")
        st.info("âš ï¸ Ollama ì—†ì´ë„ í…ìŠ¤íŠ¸ ë¬¸ì„œ ì²˜ë¦¬ëŠ” ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    # ëª¨ë¸ ìƒíƒœ í™•ì¸
    models = get_ollama_models()
    if ollama_status:
        if 'llava' in str(models).lower():
            st.success("ğŸ‘ï¸ LLaVA ëª¨ë¸ ì¤€ë¹„ë¨")
        else:
            st.warning("âš ï¸ LLaVA ëª¨ë¸ ì—†ìŒ")
            st.code("ollama pull llava")
        
        # ì–¸ì–´ ëª¨ë¸ ê°ì§€ (í•œêµ­ì–´ ìš°ì„ )
        language_models = []
        for model in models:
            if any(keyword in model.lower() for keyword in ['llama', 'gemma', 'qwen', 'mistral', 'code']):
                language_models.append(model)
        
        if language_models:
            st.success("ğŸ§  ì–¸ì–´ëª¨ë¸ ì¤€ë¹„ë¨")
            # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì–¸ì–´ ëª¨ë¸ í‘œì‹œ
            if 'current_language_model' in st.session_state:
                current_model = st.session_state.current_language_model
                if 'gemma2' in current_model.lower() or 'qwen' in current_model.lower():
                    st.success(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš°ì„ : {current_model}")
                else:
                    st.info(f"í˜„ì¬ ì‚¬ìš©: {current_model}")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ëª¨ë¸ ëª©ë¡ í‘œì‹œ
            with st.expander("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ëª¨ë¸"):
                for model in language_models:
                    if 'gemma2' in model.lower() or 'qwen' in model.lower():
                        st.success(f"ğŸ‡°ğŸ‡· {model} (í•œêµ­ì–´ ìš°ìˆ˜)")
                    elif 'llama' in model.lower():
                        st.info(f"ğŸ¤– {model} (ì˜ì–´ ì¤‘ì‹¬)")
                    else:
                        st.info(f"ğŸŒ {model}")
        else:
            st.warning("âš ï¸ ì–¸ì–´ëª¨ë¸ ì—†ìŒ")
            st.code("ollama pull gemma2:9b")
            st.info("ğŸ’¡ í•œêµ­ì–´ ì§€ì›ì„ ìœ„í•´ gemma2:9b ëª¨ë¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    st.markdown("---")
    st.markdown("## ğŸ“ ì§€ì› íŒŒì¼ í˜•ì‹")
    st.info("""
    â€¢ **í…ìŠ¤íŠ¸**: .txt, .md
    â€¢ **PDF**: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì¶”ì¶œ
    â€¢ **ì´ë¯¸ì§€**: .jpg, .png, .gif ë“±
    """)

# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
if 'rag_system' not in st.session_state:
    try:
        with st.spinner("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ëª¨ë¸ ìë™ ê°ì§€
            available_models = get_ollama_models()
            language_model = None
            
            # í•œêµ­ì–´ ì§€ì› ìš°ìˆ˜ ëª¨ë¸ ìš°ì„  ì„ íƒ (ìš°ì„ ìˆœìœ„ ìˆœ)
            korean_priority_models = [
                'gemma2:9b',      # í•œêµ­ì–´ ì§€ì› ìš°ìˆ˜
                'qwen2.5:7b',     # í•œêµ­ì–´ ì§€ì› ìš°ìˆ˜
                'codellama:7b',   # ë‹¤êµ­ì–´ ì§€ì›
                'mistral:7b',     # ë‹¤êµ­ì–´ ì§€ì›
            ]
            
            # ìš°ì„ ìˆœìœ„ ëª¨ë¸ ì¤‘ì—ì„œ ì°¾ê¸°
            for priority_model in korean_priority_models:
                if any(priority_model.split(':')[0] in model.lower() for model in available_models):
                    language_model = priority_model
                    break
            
            # ìš°ì„ ìˆœìœ„ ëª¨ë¸ì´ ì—†ìœ¼ë©´ llama ê³„ì—´ ëª¨ë¸ ì°¾ê¸°
            if not language_model:
                for model in available_models:
                    if 'llama' in model.lower():
                        language_model = model
                        break
            
            if not language_model:
                # ê¸°ë³¸ê°’ ì„¤ì •
                language_model = "gemma2:9b"
                st.warning(f"âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ '{language_model}'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                st.info("ğŸ’¡ í•œêµ­ì–´ ì§€ì›ì„ ìœ„í•´ gemma2:9b ëª¨ë¸ì„ ì„¤ì¹˜í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            else:
                if 'gemma2' in language_model.lower() or 'qwen' in language_model.lower():
                    st.success(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš°ì„  ëª¨ë¸ '{language_model}'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤!")
                else:
                    st.info(f"ğŸ¤– ì–¸ì–´ ëª¨ë¸ '{language_model}'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            st.session_state.rag_system = MultimodalRAG(llm_model=language_model)
            st.session_state.documents_added = False
            st.session_state.current_language_model = language_model
            
        st.success("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        st.stop()

# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
st.markdown("## ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")

uploaded_files = st.file_uploader(
    "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
    type=['txt', 'md', 'pdf', 'jpg', 'jpeg', 'png', 'gif', 'bmp'],
    accept_multiple_files=True,
    help="í…ìŠ¤íŠ¸, PDF, ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
)

# íŒŒì¼ ì²˜ë¦¬
if uploaded_files and st.button("ğŸ“š ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘", type="primary"):
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    successful_files = []
    failed_files = []
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = (i + 1) / len(uploaded_files)
            progress_bar.progress(progress)
            status_text.text(f"ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            suffix = Path(uploaded_file.name).suffix
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                temp_path = tmp_file.name
            
            # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
            if suffix.lower() == '.pdf':
                st.session_state.rag_system.add_pdf_document(temp_path)
            elif suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                st.session_state.rag_system.add_image_document(temp_path)
            elif suffix.lower() in ['.txt', '.md']:
                st.session_state.rag_system.add_text_document(temp_path)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {suffix}")
            
            successful_files.append(uploaded_file.name)
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            os.unlink(temp_path)
            
        except Exception as e:
            failed_files.append((uploaded_file.name, str(e)))
            if 'temp_path' in locals():
                try:
                    os.unlink(temp_path)
                except:
                    pass
    
    # ì²˜ë¦¬ ê²°ê³¼
    progress_bar.empty()
    status_text.empty()
    
    if successful_files:
        st.session_state.documents_added = True
        st.success(f"âœ… {len(successful_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
        
        with st.expander("ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡"):
            for filename in successful_files:
                st.write(f"âœ… {filename}")
    
    if failed_files:
        st.error(f"âŒ {len(failed_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
        with st.expander("ì‹¤íŒ¨í•œ íŒŒì¼ ëª©ë¡"):
            for filename, error in failed_files:
                st.write(f"âŒ {filename}: {error}")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    if hasattr(st.session_state.rag_system, 'get_status'):
        status = st.session_state.rag_system.get_status()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“„ í…ìŠ¤íŠ¸ ë¬¸ì„œ", status.get('text_documents', 0))
        with col2:
            st.metric("ğŸ–¼ï¸ ì´ë¯¸ì§€", status.get('image_documents', 0))
        with col3:
            st.metric("ğŸ§  ì´ ë¬¸ì„œ", status.get('total_documents', 0))

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# ì§ˆë¬¸ ì„¹ì…˜
if st.session_state.get('documents_added', False):
    st.markdown("---")
    st.markdown("## ğŸ’¬ ì±„íŒ…í˜• ì§ˆë¬¸í•˜ê¸°")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.chat_history:
        if message['role'] == 'user':
            with st.chat_message("user"):
                st.write(message['content'])
        else:
            with st.chat_message("assistant"):
                st.write(message['content'])
                
                # ë©”íƒ€ ì •ë³´ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                if 'confidence' in message:
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ğŸ¯ ì‹ ë¢°ë„", f"{message['confidence']:.1%}")
                    with col2:
                        st.metric("ğŸ“š ì°¸ì¡° ì†ŒìŠ¤", message.get('source_count', 0))
                
                # ì°¸ì¡° ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                if 'sources' in message and message['sources']:
                    with st.expander("ğŸ“š ì°¸ì¡°ëœ ì†ŒìŠ¤ ë³´ê¸°"):
                        for i, doc in enumerate(message['sources']):
                            st.markdown(f"**ì†ŒìŠ¤ {i+1}:**")
                            
                            # ë©”íƒ€ë°ì´í„°
                            metadata = doc.metadata
                            source_type = metadata.get('type', 'ì•Œ ìˆ˜ ì—†ìŒ')
                            source_name = metadata.get('filename', metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ'))
                            
                            st.write(f"ğŸ“„ **ìœ í˜•**: {source_type}")
                            st.write(f"ğŸ“ **íŒŒì¼**: {Path(source_name).name}")
                            
                            # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                            content = doc.page_content[:300]
                            if len(doc.page_content) > 300:
                                content += "..."
                            
                            st.text_area(
                                f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° {i+1}",
                                content,
                                height=100,
                                key=f"source_{i}_{message.get('timestamp', 0)}",
                                disabled=True
                            )
                            st.markdown("---")
    
    # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
    st.markdown("**ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸:**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š ë¬¸ì„œ ìš”ì•½", key="summary_btn"):
            st.session_state.example_query = "ì—…ë¡œë“œëœ ëª¨ë“  ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”."
    
    with col2:
        if st.button("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì„¤ëª…", key="image_btn"):
            st.session_state.example_query = "ì´ë¯¸ì§€ì—ì„œ ë°œê²¬ë˜ëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    
    with col3:
        if st.button("ğŸ” ìƒì„¸ ë¶„ì„", key="analysis_btn"):
            st.session_state.example_query = "ë¬¸ì„œì™€ ì´ë¯¸ì§€ë¥¼ ì¢…í•©í•˜ì—¬ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”."
    
    # ìƒˆë¡œìš´ ì§ˆë¬¸ ì…ë ¥ (ì±„íŒ… í˜•íƒœ)
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.chat_history.append({
            'role': 'user',
            'content': prompt,
            'timestamp': len(st.session_state.chat_history)
        })
        
        # ë‹µë³€ ìƒì„±
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                result = st.session_state.rag_system.search(prompt)
                
                # AI ë‹µë³€ì„ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.chat_history.append({
                    'role': 'assistant',
                    'content': result.answer,
                    'confidence': result.confidence,
                    'source_count': len(result.sources),
                    'sources': result.sources,
                    'timestamp': len(st.session_state.chat_history)
                })
                
                # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ìµœì‹  ëŒ€í™” í‘œì‹œ
                st.rerun()
                
            except Exception as e:
                st.error(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ì˜ˆì‹œ ì¿¼ë¦¬ ì´ˆê¸°í™”
        if 'example_query' in st.session_state:
            del st.session_state.example_query
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ë²„íŠ¼
    if st.session_state.chat_history:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°", key="clear_chat"):
            st.session_state.chat_history = []
            st.rerun()

else:
    st.info("ğŸ‘† íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•œ í›„ì— ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ì‚¬ìš© ê°€ì´ë“œ
    st.markdown("### ğŸ¯ ì‚¬ìš© ê°€ì´ë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **ğŸ“„ ì§€ì› íŒŒì¼:**
        â€¢ í…ìŠ¤íŠ¸ íŒŒì¼ (.txt, .md)
        â€¢ PDF ë¬¸ì„œ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
        â€¢ ì´ë¯¸ì§€ íŒŒì¼ (jpg, png ë“±)
        """)
    
    with col2:
        st.markdown("""
        **ğŸ¤– ê¸°ëŠ¥:**
        â€¢ í…ìŠ¤íŠ¸ ë¬¸ì„œ ê²€ìƒ‰
        â€¢ ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„ (Ollama í•„ìš”)
        â€¢ ë©€í‹°ëª¨ë‹¬ í†µí•© ê²€ìƒ‰
        """)

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("### ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´")

col1, col2 = st.columns(2)

with col1:
    st.info("""
    **ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ:**
    â€¢ LangChain + ChromaDB
    â€¢ Sentence Transformers
    â€¢ Ollama (ì„ íƒì‚¬í•­)
    """)

with col2:
    st.info("""
    **ğŸ’¡ íŒ:**
    â€¢ ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œ ê°€ëŠ¥
    â€¢ Ollama ì—†ì´ë„ ê¸°ë³¸ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥
    â€¢ ì´ë¯¸ì§€ ë¶„ì„ì€ LLaVA ëª¨ë¸ í•„ìš”
    """)